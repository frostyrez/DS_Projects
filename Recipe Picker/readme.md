### Picking popular recipes

In this project, a dataset containing a list of recipes with nutritional information, serving size, and category is analysed. Some of these recipes generated high traffic to other parts of the website, and the client would like to know if a new recipe will be high-traffic based on these features.

## Correlations
Potential correlations between features and classes (high-traffic or low-traffic) were explored. One hypothesis was that recipes high in sugar or protein were more likely to generate high traffic. However, when the quantitative features were plotted against each other using a pairplot, no direct correlation was observed.

![pairplot](https://github.com/frostyrez/DS_Projects/assets/123249055/1762690c-a0b8-4af9-8465-84127d5f400d)

The next step was looking into whether the serving size had an effect on the traffic. Based on the following plot, although there were more recipes with a particular serving size than others, no specific quantity had a higher proportion of high-traffic recipes.

![servings_hist](https://github.com/frostyrez/DS_Projects/assets/123249055/5bc10cc9-ea2d-4926-a8fa-5df17acbad1f)

Finally, the category of recipe was explored. The nested pie chart below was constructed. It can be seen from the outer wedges that each recipe category is roughly equally represented, however the popularity of each category strongly varies. Vegetable, Potato and Pork recipes all generated high traffic over 90% of the time, where as Beverage recipe only generated high traffic 5% of the time. This could provide a decent starting point for a naive model that would predict high-traffic labels purely on the recipe category.

![nested_pie](https://github.com/frostyrez/DS_Projects/assets/123249055/6f270390-ea1c-468b-801a-75db90d4d4ae)

# Logistic Regression Model
Logistic Regression is an simple, fast, and efficient tool for binary classification models. RandomizedSearchCV was used to tune the hyperparameters, however the default settings were found to be not far from optimal, with only the maximum number of iterations `max_iter` being adjusted. However, the default settings of the Logistic Regression model only provided a precision of 77%, which was below the client's requirement of 80%. Because it was only important to predict high-traffic labels correctly, with less regard to correctly predicting low-traffic recipes, the **class weights** of the model could be tweaked to meet the client's requirement. However, this was at the expense of a smaller pool of potential recipes to display on the home page. This trade-off is illustrated below:

![prec_v_perc](https://github.com/frostyrez/DS_Projects/assets/123249055/0e948e37-3435-4912-8980-34d9b127bef8)

A variety of weight ratios are tested, from 1:1 to 3:1. As the precision (i.e. number of true positives / true and false positives) increases, the number of recipes predicted as high-traffic decreases as well. Using a weight ratio of 3:1 increases precision from 77% to 89%, but nearly halves the number of suggested recipes, from 65% of the test set to 36%.

# Further Analysis of Predictions
In this section, the predictions generated by the Logistic Regression model are explored, in particular what characterises the recipes chosen by the model to be displayed on the home page.

The pie chart on the left shows the distribution of recipe types for equal class weights, and on the right for 3:1 class weights. The titles also reference the precision scores from Fig. 4 above.

![two_pies](https://github.com/frostyrez/DS_Projects/assets/123249055/6e3b2a86-231d-4db4-8a41-3d22753da525)
